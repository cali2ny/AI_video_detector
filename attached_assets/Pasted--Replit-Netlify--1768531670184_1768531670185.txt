당신은 시니어 풀스택 웹 개발자이자 머신러닝·컴퓨터비전 엔지니어입니다. Replit 환경에서 개발하고 Netlify로 배포할 웹 서비스를 만들어야 합니다. 내가 만들고 싶은 서비스는 사용자가 YouTube 영상 URL을 입력하면, 영상의 텍스트 메타데이터가 아니라 **화면 정보(썸네일/프레임)**와 딥러닝 기반 탐지 알고리즘을 활용해서 “AI 생성 영상일 가능성”을 점수로 보여주는 웹 서비스입니다. 서비스 작업용 이름은 “AI Video Inspector”입니다. 이번 버전에서는 파일 업로드나 제목 기반 분석은 사용하지 않습니다. 제목(title)은 탐지 알고리즘에서 완전히 제외해 주세요. 대신, ① 유튜브 영상의 썸네일/프레임 이미지와 ② 필요하다면 길이(duration)·채널명 정도의 보조 메타데이터, 그리고 ③ 외부 딥러닝 기반 deepfake/AI-generated detection API를 주요 신호로 사용해 주세요.

전체 스택은 프론트엔드는 React + TypeScript + Vite, 스타일은 Tailwind CSS, 백엔드는 Netlify Functions(Node.js/TypeScript)입니다. 빌드 결과물은 dist 디렉터리에 나오도록 하고, Netlify에서 그대로 빌드/배포 가능한 구조와 netlify.toml 설정까지 포함해 주세요.

백엔드의 핵심은 “탐지 알고리즘”입니다. 이 부분을 다음과 같은 3단 구조로 설계해 주세요. 첫 번째 레이어는 프레임 기반 간단 휴리스틱/주파수 분석 레이어입니다. 유튜브 videoId로부터 썸네일 URL(예: https://img.youtube.com/vi/
<videoId>/maxresdefault.jpg 또는 적절한 해상도)을 얻고, 필요하다면 한두 개의 추가 썸네일/프레임을 사용할 수 있도록 확장 가능한 구조로 짜 주세요. Node.js 환경에서 처리 가능한 범위 내에서, 각 이미지에 대해 밝기 분포, 색상 히스토그램, 블록 노이즈, 경계선(에지) 밀도, 고주파 성분 비율 등 간단한 특성을 계산해서 **“너무 과도하게 매끈한 화면, 과한 선명도/노이즈, 이상하게 균일한 텍스처”**를 감지하는 가벼운 휴리스틱 점수를 만드세요. 이 점수는 0~100 범위의 heuristicScore로 정규화하고, 구현은 현실적인 범위에서 창의적으로 설계해도 됩니다. 중요한 것은 “직접 영상 픽셀을 보고 뭔가 통계/주파수적인 특징을 본다”는 구조가 코드에 드러나는 것입니다.

두 번째 레이어는 외부 딥러닝 기반 탐지 API 레이어입니다. 여기서 당신은 먼저, 현재 사용 가능한 deepfake/AI-generated content detection API들 중에서 이미지/영상 입력을 받아 deepfake/AI-generated 점수를 float(0~1) 또는 0~100으로 반환하는 REST API를 하나 선택하거나, 그런 API를 가정한 래퍼를 설계해야 합니다. 예시로는 Hive, Sightengine, Reality Defender, EdenAI, Deepware 같은 상용·클라우드 deepfake/AI detection 서비스들이 있습니다. 실제 어떤 서비스를 쓸지는 나중에 내가 결정할 것이므로, 지금 단계에서는 다음과 같이 구현해 주세요.

환경 변수로 AI_DETECT_API_BASE_URL과 AI_DETECT_API_KEY를 읽어오고, 둘 다 존재할 때만 외부 API를 호출합니다. 2) 썸네일(또는 선택된 여러 프레임)의 URL 리스트를 받아서, POST 요청으로 { frames: string[] } 형태의 JSON을 전송하는 callExternalDetectionApi(frames: string[]): Promise<number | null> 함수를 작성합니다. 3) 응답 형식은 { probability: number }처럼 0~1 사이의 확률값을 가진다고 가정하고, 이를 0~100으로 곱해 externalScore로 사용합니다. 4) 네트워크 오류나 환경 변수 미설정 시에는 에러를 던지지 말고 null을 반환하는 “fail-soft” 동작으로 구현해 주세요. 실제 상용 API 이름, 엔드포인트 경로, 파라미터 이름 등은 적당한 가상 값으로 잡아도 괜찮지만, 코드 구조·타입 정의·에러 처리 흐름은 실제 서비스에 바로 연결하기 좋은 수준으로 완성도 있게 만들어 주세요.

세 번째 레이어는 점수 결합 및 해석 레이어입니다. 여기서 최종적으로 사용자에게 보여줄 finalScore와 label, reasons, tips를 만듭니다. 타입 정의는 src/types/analysis.ts에 AnalyzeVideoRequest와 AnalyzeVideoResponse 타입을 두고, AnalyzeVideoRequest는 videoUrl: string만 가지면 됩니다. AnalyzeVideoResponse는 score: number(0~100), label: "LIKELY_AI" | "UNCLEAR" | "LIKELY_HUMAN", reasons: string[], tips: string[], meta: { sourceType: "YOUTUBE_URL"; videoId: string; durationSeconds?: number; channelTitle?: string; }, debug: { heuristicScore: number; externalApiScore: number | null; finalScore: number; }를 포함하도록 해 주세요.

점수 결합 규칙은 다음과 같습니다. 먼저 heuristicScore를 0~100 사이 값으로 계산합니다. 외부 API 호출 결과가 있다면 externalApiScore 역시 0~100으로 사용합니다. 둘 다 있을 때는 finalScore = heuristicScore * 0.3 + externalApiScore * 0.7처럼 딥러닝 결과에 더 높은 가중치를 두고 가중 평균을 내고, 외부 점수가 없을 때는 finalScore = heuristicScore만 사용합니다. 마지막에는 0~100 범위로 clamp 해 주세요. finalScore가 70 이상이면 "LIKELY_AI", 40 이하이면 "LIKELY_HUMAN", 그 사이는 "UNCLEAR"로 label을 정합니다. reasons 배열에는 휴리스틱 분석에서 사용한 특징(예: “얼굴과 배경의 질감이 과도하게 매끈하게 나타나며, 고주파 성분이 비정상적으로 낮습니다.”, “프레임 전반에 샤프닝/노이즈 패턴이 강하게 존재해 생성형 모델에서 자주 보이는 아티팩트로 추정됩니다.”)과 외부 API에서 받은 점수에 대한 해석(“딥러닝 기반 탐지 모델이 이 콘텐츠를 X% 확률로 AI 생성으로 분류했습니다.”)을 사람이 읽기 좋은 문장으로 3~6개 정도 담아 주세요. tips에는 사용자가 직접 영상을 볼 때 확인해 볼 만한 포인트를 3~4개 정도 제안해 주세요(예: 프레임마다 손가락/악세서리가 깨지지 않는지, 입 모양과 음성이 맞는지, 배경 소품이 프레임 사이에서 불연속적으로 변하지 않는지 등).

프론트엔드는 React + TypeScript + Vite를 사용하고, Tailwind로 간단하면서 신뢰감 있는 UI를 만들어 주세요. 최상단에 서비스명과 간단한 설명이 있는 헤더가 있고, 메인 영역에는 YouTube URL 입력 필드와 “분석하기” 버튼이 있는 폼이 있습니다. 사용자가 URL을 입력하고 버튼을 누르면 /api/analyze로 POST 요청을 보내고, AnalyzeVideoResponse를 받아서 결과 섹션에 렌더링합니다. 로딩 중에는 “분석 중입니다…”와 스피너를 보여주고, 에러 시에는 “유효한 YouTube URL인지 확인해 주세요.”처럼 명확한 메시지를 띄워 주세요. 결과 섹션에서는 finalScore를 크게 숫자로 보여주고, label에 따라 색깔과 문구를 달리해서 상태를 표현하며, 게이지(Progress bar 또는 원형 게이지)로 시각화해 주세요. reasons는 카드 리스트로, tips는 체크 리스트 스타일로 보여 주고, 하단에는 “다른 영상 분석하기” 버튼을 둬서 상태를 초기화할 수 있게 해 주세요.

프로젝트 구조는 src/components, src/hooks, src/types, src/utils 등을 나누고, useAnalyzeVideo라는 커스텀 훅에서 입력 URL, 로딩, 에러, 결과 상태를 관리하게 해 주세요. Netlify Functions 디렉터리에는 analyze-video.ts를 두고, netlify.toml에는 빌드 설정과 Functions 설정, /api/analyze를 /.netlify/functions/analyze-video로 리다이렉트하는 규칙을 포함해 주세요. 전체적으로 Replit에서 npm install, npm run dev로 바로 실행 가능하고, Netlify에서 그대로 빌드/배포 가능한 수준의 완성도 있는 예시 프로젝트를 만들어 주세요. 특히 중요한 점은 제목(title)을 전혀 사용하지 않고, 화면 기반 휴리스틱과 외부 딥러닝 탐지 API를 결합해 “AI 생성 영상일 가능성”을 추정하는 구조가 코드와 타입 정의, 함수 이름, 주석에 분명하게 드러나는 것입니다.